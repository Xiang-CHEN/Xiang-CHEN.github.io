---
layout: post
title: 机器学习（长期更新）
date: 2016-02-14
categories: 右旋粒子
tag: ML
---

# 机器学习的概念

代码本身不能完全决定程序功能。通过训练集学习，代码可以在某个标准下更好地完成某项任务。

# 监督学习

## 回归 regression

输出为连续值的学习问题。线性回归，多项式回归。最小二乘法作为目标。

可以用梯度下降法作为数值计算的方法。

对于线性回归，可以用解析的方法求解（normal equation）。但是当特征的数目非常多（多于上万）时，计算复杂度极高。

## 分类 classification

输出为离散值的学习问题。

### 逻辑回归

逻辑回归的假设函数：
$$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}=P\{y=1|x;\theta\}$$

代价函数：
$$
\begin{cases}
-\log(h_\theta(x)) & \text{if } y=1\\
-\log(1-h_\theta(x)) & \text{if } y=0
\end{cases}
$$

或
$$-y\log(h_\theta(x))-(1-y)\log(1-h_\theta(x))$$

在计算最优参数时，梯度下降、特征缩放等方法依然适用。

如果要对多元分类问题采用逻辑回归，可以采用一对余的方法。

### 神经网络

非线性分类器。层数越多就越能总结出复杂的特征。目标函数非凸，所以可能收敛在局部最优。

前向传播：逻辑回归相当于没有隐层的前向传播神经网络。

学习最优参数的算法：反向传播。

1. 确认网络结构。比较常见的是 1 层隐层。如果多于 1 层隐层，一般隐层的单元数均相同。
2. 随机初始化参数。神经网络的参数不能像逻辑回归那样设置 0 为初始值，必须要打破参数的对称性。一般采用接近 0 的随机数。
3. 撰写数值程序的过程中，很可能会犯一些错误，而有错误的程序也可能可以收敛。可以使用梯度检验的方法检查代码，将算法得到的梯度和数值计算的梯度（差分）进行比较。

### 支持向量机

利用核函数可引入非线性特征。

### 朴素贝叶斯

# 无监督学习

训练集中的样本并没有被标记。

## 聚类 clustering

分解出客户群、社交网络中的子网络、数据中心中的集群

### K-means

随机化初始点（随机选取样本点），反复迭代：
1、确定点的类别；2、确定中心位置。

问题：

- 可能陷入局部最优，一种解决方法是采用不同的初始点运行算法，取最优结果。
- 算法需要预先给出聚类的类数。一种方法是 elbow method：如果最优目标值和类数的关系图中有明显的“肘点”，则取“肘点”为类数。

特殊情形：

- 类与类本身不够分离（T-shirt sizing）

# 降维

目的：压缩数据量、计算量，获得直观

## 主成分分析

预处理：Feature Scaling and Mean Normalization。

k（压缩维度）的选择原则：保留 99% 的信息。

# 应用

## 异常检测 anomaly detection

场景：产品是否合格、行为是否异常

算法：

1. 选择特征
2. 根据样本进行参数估计（譬如最大似然）
3. 对新样本进行概率计算，如果出现概率过小，认为异常发生
4. 如果有标记了的异常样本，全部放在交叉验证集和测试集中

什么时候用异常检测而不是监督学习：

1. 正样本数目极少
2. 正样本并不是一类，因而只应对负样本进行建模

## 推荐系统 recommender systems

### 基于内容的推荐

需要给每部电影设置内容特征（喜剧成分、爱情成分、动作成分）

### 协同过滤

联合优化电影的内容特征以及用户的偏好

可以用梯度向量法，或者低秩矩阵分解进行求解。

## 在线学习

如果新的数据不停地在生成、老的数据的重要性逐渐降低而且不需要再次处理时，采用。

# 机器学习的系统设计

1. 收集数据
2. 选取特征，测试算法
- 先实现简单算法快速尝试
- 把数据集分为训练集、验证集和测试集（典型的分派比例为 3:1:1）：用验证集选择模型（特征、多项式阶数、正则系数），用测试集确定性能。
- 梯度下降法的实际操作技巧：
    1. Feature Scaling and Mean Normalization。使得不同特征的数值的量纲大体相当，梯度下降的震荡更少、收敛更快。
    2. 学习率（步长）的设置。如果目标函数会增加，需要减少步长；如果收敛速度太慢，需要增加步长。
- 准确率/召回率：但是准确率的指标并不足以很好地衡量算法的好坏，如 skewed classes（不同类别的样本数量差别巨大）的情况。然而准确率和召回率存在折中关系。一个组合两者的指标是 F score：$\frac{2PR}{P+R}$。F 值倾向于使两者都不要太低。
3. 改进效果
- 误差分析：人工检查错误，看看有哪些主要的因素，以帮助改进算法/特征
- 如果所选特征足以预测结果，所用算法的参数足够多，那么更大的数据集很可能会得到更好的结果。
- 学习曲线：训练集误差和验证集误差关于样本数的函数曲线。欠拟合：high bias，训练集误差和验证集误差都很高；过拟合：high variance，训练集误差很低，验证集误差很高。
- 过拟合的解决方法：
   1. 减少特征数目（手动挑选或算法挑选）
   2. 正则化，把需要压缩的特征的参数作为惩罚项加入目标函数中。

